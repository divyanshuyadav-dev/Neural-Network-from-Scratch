{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T00:02:54.447837Z","iopub.execute_input":"2026-01-15T00:02:54.448973Z","iopub.status.idle":"2026-01-15T00:02:54.454421Z","shell.execute_reply.started":"2026-01-15T00:02:54.448942Z","shell.execute_reply":"2026-01-15T00:02:54.453438Z"}},"outputs":[],"execution_count":121},{"cell_type":"code","source":"in_feat = np.array(\n    [\n        #batch 1:\n        [\n            # channel 1\n            [\n                [1, 2, 3, 4],\n                [0, 1, 0, 1],\n                [1, 2, 3, 4],\n                [0, 1, 0, 1],\n            ],\n            \n            # channel 2\n            [\n                [2, 3, 4, 5],\n                [1, 2, 1, 2],\n                [2, 3, 4, 5],\n                [1, 2, 1, 2],\n            ],\n\n            # channel 3\n            [\n                [3, 4, 5, 6],\n                [2, 3, 2, 3],\n                [3, 4, 5, 6],\n                [2, 3, 2, 3],\n            ],\n        ]\n    ], \ndtype=np.float64)\n\n\n\nfilter = np.array(\n    [\n        [\n            [ 2, 2],\n            [ 2, 2]\n        ],\n        [\n            [ 1, 1],\n            [ 1, 1]\n        ],\n        [\n            [ 0, 0],\n            [ 0, 0]\n        ]\n    ]\n)\n# padding = 1\n# new_in_feat = np.zeros( (in_feat.shape[0],in_feat.shape[1], in_feat.shape[2]+padding*2, in_feat.shape[3]+padding*2))\n# for batch in range(in_feat.shape[0]):\n#     for channel in range(in_feat.shape[1]):\n#         new_in_feat[batch][channel] = np.pad(in_feat[batch][channel], pad_width=padding)\n# in_feat = new_in_feat\n\nprint(in_feat)\n# print(\"--\"*5)\n# print(new_in_feat)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T00:02:54.487881Z","iopub.execute_input":"2026-01-15T00:02:54.488147Z","iopub.status.idle":"2026-01-15T00:02:54.497556Z","shell.execute_reply.started":"2026-01-15T00:02:54.488130Z","shell.execute_reply":"2026-01-15T00:02:54.496201Z"}},"outputs":[{"name":"stdout","text":"[[[[1. 2. 3. 4.]\n   [0. 1. 0. 1.]\n   [1. 2. 3. 4.]\n   [0. 1. 0. 1.]]\n\n  [[2. 3. 4. 5.]\n   [1. 2. 1. 2.]\n   [2. 3. 4. 5.]\n   [1. 2. 1. 2.]]\n\n  [[3. 4. 5. 6.]\n   [2. 3. 2. 3.]\n   [3. 4. 5. 6.]\n   [2. 3. 2. 3.]]]]\n","output_type":"stream"}],"execution_count":122},{"cell_type":"code","source":"class Convolution_Layer:\n# input feature shape (batch_size, c_in, h_in, w_in)\n# Kernal/Filter Shape = (h_filter, w_filter, c_in)\n# n-Kernal/Filters Shape = (n_filter, h_filter, w_filter, c_in)\n# output feature shape (batch_size, c_out, h_out, w_out)\n\n    def __init__(self, n_filter, h_filter, w_filter, stride=1, padding=0):\n        self.n_filter = n_filter # no of filters to apply\n        self.h_filter = h_filter # filter height\n        self.w_filter = w_filter # filter width\n        self.stride = stride\n        self.padding = padding\n        self.conv_filter = None\n        \n    \n    def forward(self, input_feature):\n        \n        batch_size = input_feature.shape[0]\n        \n        c_in = input_feature.shape[1]\n        h_in = input_feature.shape[2]\n        w_in = input_feature.shape[3]\n\n        c_out = self.n_filter # NOTE: the number of output feature channle is equal to the number of filters applied\n        h_out = int( (h_in - self.h_filter + 2 * self.padding)  /self.stride + 1 )\n        w_out = int( (w_in - self.w_filter + 2 * self.padding) / self.stride + 1 )\n        \n        # declare filters only once (not in every forward pass)\n        if self.conv_filter is None:\n            # NOTE: no of filter channel = no of input channel\n            self.conv_filter = np.ones( (self.n_filter, c_in, self.h_filter, self.w_filter) ) #TODO: use apt initialisation strategy\n        \n        # declare output feature map/ activaiton map, NOTE: no of output channel = no of filters applied\n        output_feature = np.zeros( (batch_size, c_out, h_out, w_out) )\n\n        \n        # channel wise padding\n        if(self.padding > 0):\n            temp_pad = np.zeros( (batch_size, c_in, h_in+self.padding*2, w_in+self.padding*2) )\n            for b in range(batch_size):\n                for c in range(c_in):\n                    temp_pad[b][c] = np.pad(input_feature[b][c], pad_width = self.padding)\n            input_feature = temp_pad\n            h_in = input_feature.shape[2]\n            w_in = input_feature.shape[3]\n            \n\n        # Convolving\n        for b_id in range(batch_size): #for each batch\n            for ch_or_kr_id in range(c_out): #for each filter or output_channel\n                for i in range(h_out): # for each row\n                    for j in range(w_out):# for each col\n                        scaler_sum = 0;\n                        for a in range(c_in): #for each filter channel (same as input channel)\n                            for b in range(self.h_filter): # for each row of filter\n                                for c in range(self.w_filter): # for each col of filter\n                                    scaler_sum += self.conv_filter[ch_or_kr_id][a][b][c] * input_feature[b_id][a][b + i*self.stride][c + j*self.stride] # (b+i*stride and c+j*stride should ensure filter sliding)\n                        output_feature[b_id][ch_or_kr_id][i][j] = scaler_sum\n        # return the activation map\n        return output_feature                                  \n                \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T00:02:54.530073Z","iopub.execute_input":"2026-01-15T00:02:54.530414Z","iopub.status.idle":"2026-01-15T00:02:54.543804Z","shell.execute_reply.started":"2026-01-15T00:02:54.530388Z","shell.execute_reply":"2026-01-15T00:02:54.542621Z"}},"outputs":[],"execution_count":123},{"cell_type":"code","source":"conv = Convolution_Layer(n_filter=1, h_filter=2, w_filter=2, stride=1, padding=1)\nout_feat = conv.forward(in_feat)\nprint(in_feat)\nprint(\"input shape:\", in_feat.shape, \"\\n\")\n\nprint(conv.conv_filter)\nprint(\"filter shape\", conv.conv_filter.shape, \"\\n\")\n\nprint(out_feat)\nprint(\"output shape:\", out_feat.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T00:03:23.667144Z","iopub.execute_input":"2026-01-15T00:03:23.667517Z","iopub.status.idle":"2026-01-15T00:03:23.677688Z","shell.execute_reply.started":"2026-01-15T00:03:23.667491Z","shell.execute_reply":"2026-01-15T00:03:23.676402Z"}},"outputs":[{"name":"stdout","text":"[[[[1. 2. 3. 4.]\n   [0. 1. 0. 1.]\n   [1. 2. 3. 4.]\n   [0. 1. 0. 1.]]\n\n  [[2. 3. 4. 5.]\n   [1. 2. 1. 2.]\n   [2. 3. 4. 5.]\n   [1. 2. 1. 2.]]\n\n  [[3. 4. 5. 6.]\n   [2. 3. 2. 3.]\n   [3. 4. 5. 6.]\n   [2. 3. 2. 3.]]]]\ninput shape: (1, 3, 4, 4) \n\n[[[[1. 1.]\n   [1. 1.]]\n\n  [[1. 1.]\n   [1. 1.]]\n\n  [[1. 1.]\n   [1. 1.]]]]\nfilter shape (1, 3, 2, 2) \n\n[[[[ 6. 15. 21. 27. 15.]\n   [ 9. 24. 30. 36. 21.]\n   [ 9. 24. 30. 36. 21.]\n   [ 9. 24. 30. 36. 21.]\n   [ 3.  9.  9.  9.  6.]]]]\noutput shape: (1, 1, 5, 5)\n","output_type":"stream"}],"execution_count":127},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}